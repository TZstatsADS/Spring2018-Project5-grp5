{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Composing Music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step1: Import Package and Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to import functions, which helps us to clean data and train models. And we also need packages, like tensorflow, for us to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model_tb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-42e4b81b9dba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_tb\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model_tb'"
     ]
    }
   ],
   "source": [
    "import model_tb as model\n",
    "import data\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know wheteher this model is pre-trained or not. We will check for the pre-trained model, if not, the model will be trained by our model.biaxial_model function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_name = 'cache.pkl'\n",
    "model_name = None\n",
    "\n",
    "\n",
    "if not os.path.exists(cache_name):\n",
    "    composers = input(\"Enter composers separated by spaces: \").split()\n",
    "    all_pieces = {}\n",
    "\n",
    "    if len(composers)==0:\n",
    "        all_pieces.update(data.getpices(path=\"midis\", mode='all'))\n",
    "    else:\n",
    "        for c in composers:\n",
    "            all_pieces.update(data.getpices(path=\"../midis\", composer=c))\n",
    "\n",
    "    cache = data.initialize_cache(all_pieces, save_loc=cache_name)\n",
    "else:\n",
    "    with open(cache_name, 'rb') as f:\n",
    "        cache = pickle.load(f)\n",
    "\n",
    "# Build and load the pre-existing model if it exists\n",
    "print('Building model')\n",
    "music_model = model.biaxial_model(t_layer_sizes=[300,300],\n",
    "    n_layer_sizes=[100,50],\n",
    "    trainer = tf.train.RMSPropOptimizer(0.005))\n",
    "\n",
    "print('Start training')\n",
    "music_model.train(cache, batch_size=5, max_epoch=10000,\n",
    "    predict_freq=100, pre_trained_model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-trained models name is biaxial_rnn_1524342232, which is trainned by 500 pop music. We can use this model to predict music and the generated music \n",
    "\n",
    "Although the training can be run in parallel, this is not possible when performing inference. To perform inference without teacher’s forcing, the network output at each timestep is used as input for the next timestep, requiring inference to be performed sequentially. We first get an initializer seed, sampled from the starting timestep of a measure in a random piece, as the last time step information. This input is fed through one timestep in the time network and then through the entire note dimension recurrently. The output is a complete “chord” distribution for one timestep. This output is then mapped to a new set of input vectors for each note, which is then processed through the biaxial network in a similar fashion. Once a sequence of chords with the desired length has been produced, the outputs are concatenated along the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"biaxial_rnn_1524342232\"\n",
    "    \n",
    "    if not os.path.exists(cache_name):\n",
    "        composers = input(\"Enter composers separated by spaces: \").split()\n",
    "        all_pieces = {}\n",
    "        \n",
    "        if len(composers)==0:\n",
    "            all_pieces.update(data.getpices(path=\"midis\", mode='all'))\n",
    "        else:\n",
    "            for c in composers:\n",
    "                all_pieces.update(data.getpices(path=\"../midis\", composer=c))\n",
    "\n",
    "        cache = data.initialize_cache(all_pieces, save_loc=cache_name)\n",
    "    else:\n",
    "        with open(cache_name, 'rb') as f:\n",
    "            cache = pickle.load(f)\n",
    "    \n",
    "    # Building model\n",
    "    print('Building model')\n",
    "    music_model = model.biaxial_model(t_layer_sizes=[300,300], n_layer_sizes=[100,50], trainer=tf.train.RMSPropOptimizer(0.005))\n",
    "    \n",
    "    print('Start predicting')\n",
    "    music_model.predict(cache,model_name,step=320,conservativity=1,n=20,saveto='predict songs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
